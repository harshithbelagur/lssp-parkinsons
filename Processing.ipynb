{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_in_directory(directory, event_name, other_features):\n",
    "    column_names = ['Timestamp', 'Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z', 'Gyroscope_X', 'Gyroscope_Y', 'Gyroscope_Z']\n",
    "    #path = os.path.join(directory, 'timeseries')\n",
    "    path = 'pads-parkinsons-disease-smartwatch-dataset-1.0.0/movement/timeseries/'\n",
    "    file_pattern = f\"{path}/*_{event_name}.txt\"\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    first_five_seconds_list = []\n",
    "    rest_list = []\n",
    "    \n",
    "    \n",
    "    for filename in tqdm(file_list, desc=f'Processing files for event {event_name}'):\n",
    "        df = pd.read_csv(filename, delimiter=',')  \n",
    "        df.columns = column_names\n",
    "        df = df[(df['Timestamp'] > 0.5) & (df['Timestamp'] < 10.24)]\n",
    "    \n",
    "        base_name = os.path.basename(filename)\n",
    "        unique_identifier = int(base_name.replace(f\"_{event_name}.txt\", ''))\n",
    "    \n",
    "        df['Patient_ID'] = unique_identifier\n",
    "        \n",
    "        label_value = other_features.loc[other_features['id'] == unique_identifier, 'label'].iloc[0]\n",
    "        df['Label'] = label_value\n",
    "    \n",
    "    \n",
    "        first_five_seconds_data = df[df['Timestamp'] <= 5]\n",
    "        last_seconds_data = df[df['Timestamp'] > 5]\n",
    "    \n",
    "        mean_values_first_five = first_five_seconds_data[['Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z',\n",
    "                                 'Gyroscope_X', 'Gyroscope_Y', 'Gyroscope_Z']].mean()\n",
    "        mean_dict_first_five = {\n",
    "            'Accelerometer_X_mean': mean_values_first_five['Accelerometer_X'],\n",
    "            'Accelerometer_Y_mean': mean_values_first_five['Accelerometer_Y'],\n",
    "            'Accelerometer_Z_mean': mean_values_first_five['Accelerometer_Z'],\n",
    "            'Gyroscope_X_mean': mean_values_first_five['Gyroscope_X'],\n",
    "            'Gyroscope_Y_mean': mean_values_first_five['Gyroscope_Y'],\n",
    "            'Gyroscope_Z_mean': mean_values_first_five['Gyroscope_Z'],\n",
    "            'Label': df['Label'].iloc[0],\n",
    "            'Patient_ID': df['Patient_ID'].iloc[0]\n",
    "        }\n",
    "        first_five_df = pd.DataFrame([mean_dict_first_five])\n",
    "        first_five_seconds_list.append(first_five_df)\n",
    "    \n",
    "        mean_values_rest = last_seconds_data[['Accelerometer_X', 'Accelerometer_Y', 'Accelerometer_Z',\n",
    "                                 'Gyroscope_X', 'Gyroscope_Y', 'Gyroscope_Z']].mean()\n",
    "        mean_dict_rest = {\n",
    "            'Accelerometer_X_mean': mean_values_rest['Accelerometer_X'],\n",
    "            'Accelerometer_Y_mean': mean_values_rest['Accelerometer_Y'],\n",
    "            'Accelerometer_Z_mean': mean_values_rest['Accelerometer_Z'],\n",
    "            'Gyroscope_X_mean': mean_values_rest['Gyroscope_X'],\n",
    "            'Gyroscope_Y_mean': mean_values_rest['Gyroscope_Y'],\n",
    "            'Gyroscope_Z_mean': mean_values_rest['Gyroscope_Z'],\n",
    "            'Label': df['Label'].iloc[0],\n",
    "            'Patient_ID': df['Patient_ID'].iloc[0]\n",
    "        }\n",
    "        rest_df = pd.DataFrame([mean_dict_rest])\n",
    "        rest_list.append(rest_df)\n",
    "         \n",
    "    first_five_seconds_list_df = pd.concat(first_five_seconds_list, ignore_index=True)\n",
    "    rest_df = pd.concat(rest_list, ignore_index=True)\n",
    "    return first_five_seconds_list_df, rest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data(df, part):\n",
    "    df['Label'] = df['Label'].replace({1: 1, 2: 0, 0: 0})\n",
    "    df.drop(columns=['Patient_ID'], inplace=True)\n",
    "    \n",
    "    features = np.array(df.iloc[:, :-1])\n",
    "    labels = np.array(df['Label'])\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "    \n",
    "    train_label_counts = pd.Series(Y_train).value_counts(normalize=True)\n",
    "    test_label_counts = pd.Series(Y_test).value_counts(normalize=True)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_xgb(X_train, Y_train, X_test, Y_test):\n",
    "    # Initialize XGBoost classifier\n",
    "    xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.1, 0.01, 0.001]\n",
    "    }\n",
    "\n",
    "    # Define recall as the scoring metric\n",
    "    scorer = make_scorer(recall_score)\n",
    "\n",
    "    # Define stratified cross-validation strategy\n",
    "    stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform hyperparameter tuning with stratified cross-validation\n",
    "    grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring=scorer, cv=stratified_cv, n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    # Get the best hyperparameters and the best estimator\n",
    "    best_params = grid_search.best_params_\n",
    "    best_xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best estimator using cross-validation\n",
    "    cv_recall_scores = cross_val_score(best_xgb_classifier, X_train, Y_train, cv=5, scoring=scorer)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and recall on the test set\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "    return best_params, cv_recall_scores, accuracy, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_rf(X_train, Y_train, X_test, Y_test):\n",
    "    # Initialize Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Define recall as the scoring metric\n",
    "    scorer = make_scorer(recall_score)\n",
    "\n",
    "    # Define stratified cross-validation strategy\n",
    "    stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform hyperparameter tuning with stratified cross-validation\n",
    "    grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring=scorer, cv=stratified_cv, n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    # Get the best hyperparameters and the best estimator\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best estimator using cross-validation\n",
    "    cv_recall_scores = cross_val_score(best_rf_classifier, X_train, Y_train, cv=5, scoring=scorer)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and recall on the test set\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "    return best_params, cv_recall_scores, accuracy, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate a classifier\n",
    "def train_and_evaluate_classifier(X_train, Y_train, X_test, Y_test, classifier):\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    return accuracy, recall, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files for event LiftHold_LeftWrist: 100%|██████████| 469/469 [00:04<00:00, 112.36it/s]\n",
      "/var/folders/qs/j6xq3rvs41l44b9l0x4ps8k00000gn/T/ipykernel_11782/3653412071.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_data_rf_first_five.reset_index(drop=True)], ignore_index=True)\n",
      "Processing files for event StretchHold_LeftWrist: 100%|██████████| 469/469 [00:04<00:00, 116.00it/s]\n",
      "Processing files for event CrossArms_LeftWrist: 100%|██████████| 469/469 [00:03<00:00, 118.31it/s]\n",
      "Processing files for event Entrainment_RightWrist: 100%|██████████| 469/469 [00:04<00:00, 109.19it/s]\n",
      "Processing files for event PointFinger_LeftWrist: 100%|██████████| 469/469 [00:03<00:00, 124.75it/s]\n",
      "Processing files for event DrinkGlas_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 126.63it/s]\n",
      "Processing files for event TouchIndex_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 124.88it/s]\n",
      "Processing files for event DrinkGlas_LeftWrist: 100%|██████████| 469/469 [00:03<00:00, 126.79it/s]\n",
      "Processing files for event Relaxed_RightWrist: 100%|██████████| 469/469 [00:04<00:00, 111.13it/s]\n",
      "Processing files for event PointFinger_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 127.26it/s]\n",
      "Processing files for event RelaxedTask_LeftWrist: 100%|██████████| 469/469 [00:04<00:00, 113.22it/s]\n",
      "Processing files for event Entrainment_LeftWrist: 100%|██████████| 469/469 [00:04<00:00, 107.73it/s]\n",
      "Processing files for event HoldWeight_LeftWrist: 100%|██████████| 469/469 [00:03<00:00, 124.59it/s]\n",
      "Processing files for event Relaxed_LeftWrist: 100%|██████████| 469/469 [00:04<00:00, 108.54it/s]\n",
      "Processing files for event StretchHold_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 127.30it/s]\n",
      "Processing files for event TouchNose_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 124.55it/s]\n",
      "Processing files for event RelaxedTask_RightWrist: 100%|██████████| 469/469 [00:04<00:00, 110.20it/s]\n",
      "Processing files for event TouchNose_LeftWrist: 100%|██████████| 469/469 [00:03<00:00, 123.03it/s]\n",
      "Processing files for event HoldWeight_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 126.91it/s]\n",
      "Processing files for event TouchIndex_LeftWrist: 100%|██████████| 469/469 [00:03<00:00, 126.15it/s]\n",
      "Processing files for event LiftHold_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 125.09it/s]\n",
      "Processing files for event CrossArms_RightWrist: 100%|██████████| 469/469 [00:03<00:00, 125.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     File     Classifier  Accuracy    Recall        Part\n",
      "0      LiftHold_LeftWrist  Random Forest  0.542553  0.690909  first_five\n",
      "1      LiftHold_LeftWrist        XGBoost  0.500000  0.563636  first_five\n",
      "2      LiftHold_LeftWrist       LightGBM  0.425532  0.472727  first_five\n",
      "3      LiftHold_LeftWrist       Ensemble  0.500000  0.574074  first_five\n",
      "4      LiftHold_LeftWrist  Random Forest  0.531915  0.672727        rest\n",
      "..                    ...            ...       ...       ...         ...\n",
      "171  CrossArms_RightWrist       Ensemble  0.595745  0.623188  first_five\n",
      "172  CrossArms_RightWrist  Random Forest  0.574468  0.763636        rest\n",
      "173  CrossArms_RightWrist        XGBoost  0.553191  0.690909        rest\n",
      "174  CrossArms_RightWrist       LightGBM  0.585106  0.690909        rest\n",
      "175  CrossArms_RightWrist       Ensemble  0.595745  0.609375        rest\n",
      "\n",
      "[176 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "directory = 'pads-parkinsons-disease-smartwatch-dataset-1.0.0/movement/timeseries/'\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('.txt')]\n",
    "event_names = []\n",
    "# Initialize empty DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['File', 'Classifier', 'Accuracy', 'Recall'])\n",
    "\n",
    "files_starting_with_001 = [file for file in file_list if file.startswith('001')]\n",
    "\n",
    "event_names = [file.split('001_')[1].split('.txt')[0] for file in files_starting_with_001]\n",
    "\n",
    "for event_name in event_names:\n",
    "        \n",
    "    first_five, rest = process_files_in_directory(directory, event_name)\n",
    "    \n",
    "    # Preprocess and split first_five data\n",
    "    X_train_first_five, X_test_first_five, Y_train_first_five, Y_test_first_five = preprocess_and_split_data(first_five, 'first_five')\n",
    "    \n",
    "    # Preprocess and split rest data\n",
    "    X_train_rest, X_test_rest, Y_train_rest, Y_test_rest = preprocess_and_split_data(rest, 'rest')\n",
    "    \n",
    "    # Train and evaluate Random Forest classifier for first_five\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    rf_accuracy_first_five, rf_recall_first_five, rf_first_five_classifier = train_and_evaluate_classifier(X_train_first_five, Y_train_first_five, X_test_first_five, Y_test_first_five, rf_classifier)\n",
    "    new_data_rf_first_five = pd.DataFrame({'File': [event_name], 'Classifier': 'Random Forest', 'Part': 'first_five', 'Accuracy': [rf_accuracy_first_five], 'Recall': [rf_recall_first_five]})\n",
    "    # dump(rf_first_five_classifier, 'models/' + event_name + '_Random Forest_first_five.joblib')\n",
    "    results_df = pd.concat([results_df, new_data_rf_first_five.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "    # Train and evaluate XGBoost classifier for first_five\n",
    "    xgb_classifier = XGBClassifier()\n",
    "    xgb_accuracy_first_five, xgb_recall_first_five, xgb_first_five_classifier = train_and_evaluate_classifier(X_train_first_five, Y_train_first_five, X_test_first_five, Y_test_first_five, xgb_classifier)\n",
    "    new_data_xgb_first_five = pd.DataFrame({'File': [event_name], 'Classifier': 'XGBoost', 'Part': 'first_five', 'Accuracy': [xgb_accuracy_first_five], 'Recall': [xgb_recall_first_five]})\n",
    "    # dump(xgb_first_five_classifier, 'models/' + event_name + '_XGBoost_first_five.joblib')\n",
    "    results_df = pd.concat([results_df, new_data_xgb_first_five.reset_index(drop=True)], ignore_index=True)\n",
    "    \n",
    "    # Train and evaluate LightGBM classifier for first_five\n",
    "    lgb_classifier = lgb.LGBMClassifier(verbose=-1)\n",
    "    lgb_accuracy_first_five, lgb_recall_first_five, lgb_first_five_classifier = train_and_evaluate_classifier(X_train_first_five, Y_train_first_five, X_test_first_five, Y_test_first_five, lgb_classifier)\n",
    "    new_data_lgb_first_five = pd.DataFrame({'File': [event_name], 'Classifier': 'LightGBM', 'Part': 'first_five', 'Accuracy': [lgb_accuracy_first_five], 'Recall': [lgb_recall_first_five]})\n",
    "    # dump(lgb_first_five_classifier, 'models/' + event_name + '_LightGBM_first_five.joblib')\n",
    "    results_df = pd.concat([results_df, new_data_lgb_first_five.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "    #Confidence ensemble for first_five\n",
    "    voting_clf = VotingClassifier(estimators=[\n",
    "        ('rf', rf_first_five_classifier), \n",
    "        ('xgb', xgb_first_five_classifier), \n",
    "        ('lgb', lgb_first_five_classifier)\n",
    "    ], voting='soft')\n",
    "    voting_clf.fit(X_train_first_five, Y_train_first_five)\n",
    "    voting_accuracy = voting_clf.score(X_test_first_five, Y_test_first_five)\n",
    "    y_pred_first_five = voting_clf.predict(X_test_first_five)\n",
    "    voting_recall = recall_score(y_pred_first_five, Y_test_first_five)\n",
    "    ensemble_first_five = pd.DataFrame({'File': [event_name], 'Classifier': 'Ensemble', 'Part': 'first_five', 'Accuracy': [voting_accuracy], 'Recall': [voting_recall]})\n",
    "    # dump(voting_clf, 'models/' + event_name + '_Ensemble_first_five.joblib')\n",
    "    results_df = pd.concat([results_df, ensemble_first_five.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "    highest_recall = max(rf_recall_first_five, xgb_recall_first_five, lgb_recall_first_five, voting_recall)\n",
    "\n",
    "    if highest_recall == rf_recall_first_five:\n",
    "        dump(rf_first_five_classifier, 'models/' + event_name + '_first_five.joblib')\n",
    "    elif highest_recall == xgb_recall_first_five:\n",
    "        dump(xgb_first_five_classifier, 'models/' + event_name + '_first_five.joblib')\n",
    "    elif highest_recall == lgb_recall_first_five:\n",
    "        dump(lgb_first_five_classifier, 'models/' + event_name + '_first_five.joblib')\n",
    "    else: \n",
    "        dump(voting_clf, 'models/' + event_name + '_first_five.joblib')\n",
    "\n",
    "    # Train and evaluate Random Forest classifier for rest\n",
    "    rf_accuracy_rest, rf_recall_rest, rf_rest_classifier = train_and_evaluate_classifier(X_train_rest, Y_train_rest, X_test_rest, Y_test_rest, rf_classifier)\n",
    "    new_data_rf_rest = pd.DataFrame({'File': [event_name], 'Classifier': 'Random Forest', 'Part': 'rest', 'Accuracy': [rf_accuracy_rest], 'Recall': [rf_recall_rest]})\n",
    "    # dump(rf_rest_classifier, 'models/' + event_name + '_Random Forest_rest.joblib')\n",
    "    results_df = pd.concat([results_df, new_data_rf_rest.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "    # Train and evaluate XGBoost classifier for rest\n",
    "    xgb_accuracy_rest, xgb_recall_rest, xgb_rest_classifier = train_and_evaluate_classifier(X_train_rest, Y_train_rest, X_test_rest, Y_test_rest, xgb_classifier)\n",
    "    new_data_xgb_rest = pd.DataFrame({'File': [event_name], 'Classifier': 'XGBoost', 'Part': 'rest', 'Accuracy': [xgb_accuracy_rest], 'Recall': [xgb_recall_rest]})\n",
    "    # dump(xgb_rest_classifier, 'models/' + event_name + '_XGBoost_rest.joblib')\n",
    "    results_df = pd.concat([results_df, new_data_xgb_rest.reset_index(drop=True)], ignore_index=True)\n",
    "    \n",
    "    # Train and evaluate LightGBM classifier for rest\n",
    "    lgb_accuracy_rest, lgb_recall_rest, lgb_rest_classifier = train_and_evaluate_classifier(X_train_rest, Y_train_rest, X_test_rest, Y_test_rest, lgb_classifier)\n",
    "    new_data_lgb_rest = pd.DataFrame({'File': [event_name], 'Classifier': 'LightGBM', 'Part': 'rest', 'Accuracy': [lgb_accuracy_rest], 'Recall': [lgb_recall_rest]})\n",
    "    # dump(lgb_rest_classifier, 'models/' + event_name + '_LightGBM_rest.joblib')\n",
    "    results_df = pd.concat([results_df, new_data_lgb_rest.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "    #Confidence ensemble for rest\n",
    "    voting_clf = VotingClassifier(estimators=[\n",
    "        ('rf', rf_rest_classifier), \n",
    "        ('xgb', xgb_rest_classifier), \n",
    "        ('lgb', lgb_rest_classifier)\n",
    "    ], voting='soft')\n",
    "    voting_clf.fit(X_train_rest, Y_train_rest)\n",
    "    y_pred_first_five = voting_clf.predict(X_test_first_five)\n",
    "    voting_recall = recall_score(y_pred_first_five, Y_test_first_five)\n",
    "    ensemble_rest = pd.DataFrame({'File': [event_name], 'Classifier': 'Ensemble', 'Part': 'rest', 'Accuracy': [voting_accuracy], 'Recall': [voting_recall]})\n",
    "    # dump(voting_clf, 'models/' + event_name + '_Ensemble_rest.joblib')\n",
    "    results_df = pd.concat([results_df, ensemble_rest.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "    highest_recall = max(rf_recall_rest, xgb_recall_rest, lgb_recall_rest, voting_recall)\n",
    "\n",
    "    if highest_recall == rf_recall_rest:\n",
    "        dump(rf_rest_classifier, 'models/' + event_name + '_rest.joblib')\n",
    "    elif highest_recall == xgb_recall_rest:\n",
    "        dump(xgb_rest_classifier, 'models/' + event_name + '_rest.joblib')\n",
    "    elif highest_recall == lgb_recall_rest:\n",
    "        dump(lgb_rest_classifier, 'models/' + event_name + '_rest.joblib')\n",
    "    else: \n",
    "        dump(voting_clf, 'models/' + event_name + '_rest.joblib')\n",
    "        \n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('Results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
